import tensorflow as tf

# Reshape allele_freq_train and allele_freq_val to have shape (-1, 3, 1)
allele_freq_train = allele_freq_train.reshape((-1, 3, 1))
allele_freq_val = allele_freq_val.reshape((-1, 3, 1))

# Create the RNN model with LSTM layers
# Apply 30% dropout to prevent overfitting 
model = tf.keras.Sequential([
    tf.keras.layers.LSTM(128, input_shape=(3, 1), activation='tanh', return_sequences=True, recurrent_regularizer=tf.keras.regularizers.l2(0.01)),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.LSTM(128, activation='tanh', recurrent_regularizer=tf.keras.regularizers.l2(0.01) ),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(128, activation='tanh'), 
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(1, activation='tanh') 
])

# Compile the model with the MAE loss, the Adam optimiser, and the MSE performance metric
optim = tf.keras.optimizers.Adam(learning_rate=0.001, clipvalue=1.0)
model.compile(loss='mean_absolute_error', optimizer=optim, metrics=['mse'])

# Define the early stopping callback - if validation doesn't improve for 5 consecutive epochs, training will stop
early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
